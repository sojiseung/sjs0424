# 1. 머신러닝 기초

- 독립변수 : 종속변수의 변화를 가져오거나 영향을 미치는 원인 변수로써, 결과를 예측을 하게 하거나 차이를 설명하기 위해 사용되는 예측 변수이다 즉, 독립변수는 종속변수의 원인으로 추정되는 변수이다.
- 종속변수 : 독립변수의 영향으로 나타나는 결과가 되는 결과 변수로써, 독립변수의 변화에 따라 변화되는 변수이다.

예시:)
- 수입(독립변수)이 높으면 교육수준(종속변수)이 높아질 수 있다.
- 노인의 건강상태(독립변수)가 좋을수록 행복지수(종속변수)가 높다.
- 가정폭력의 경험(독립변수)이 있는 청소년은 그렇지 않은 청소녀에 비해 비행율(종속변수)이 높을 것 이다.

회귀분석의 의미
회귀분석은 종속변수(목표)와 하나 이상의 독립변수(예측 변수) 간의 미래 사건을 예측하는 방법이다. 예를 들어 난폭운전과 운전자에 의한 교통사고 총 건수 사이의 상관관계을 예측하거나 비즈니스 상황에서는 특정 금액을 광고에 사용했을 때와 그것이 판매에 미치는 영향 사이의 관계를 예측하는 데 사용할 수 있다.

머신러닝 모델의 성능을 측정하는 방법
- 분류모델 : 정확도, 정밀도, 재현율, F1 점수
- 회귀모델 : 평균 절대 오차, 회귀 작업의 평균 제곱근 오차

회귀 및 분류라는 두 가지 유형의 문제에 사용
- 회귀 : 회귀는 대상 또는 종속 변수가 연속적이거나 정렬된 전체 값일 때 사용.
- 분류 : 분류는 대상 변수가 범주형일 때, 간단히 말해서 입력 데이터를 범주로 분류할때 사용.

train, validation, test 데이터셋
머신러닝, 딥러닝 모델을 피팅시키기 위해서는 데이터셋을 크게 세 가지로 분리한다.
- training set(학습 데이터셋) : 모델의 학습을 위해 사용되는 데이터
- validation set(검증 데이터셋) : 모델의 학습 과정에서 성능을 확인하고, 하이퍼 파라미터를 튜닝하는데 사용된다. 여러가지 하이퍼 파라미터로 생성된 모델들 중에 어떤 것이 성능이 좋은지 평가한다. (하이퍼 파라미터란 최적의 훈련 모델을 구현하기 위해 모델에 설정하는 변수로 학습률, 에포크 수(훈련 반복 횟수), 가중치 초기화 등을 결정할 수 있는 모든것)
- test set(테스트 데이터셋) : 생성된 모델의 예측성능을 평가하는데 사용된다.

train / test를 분리하는 이유는 실제로는 모델을 활용하기 위해서는 학습에 사용되지 않은 데이터에 대한 예측을 잘해야한다. 만약, 주어진 데이터에만 치중하여 학습할 경우, 조금이라도 다른 패턴을 가진 데이터에 대해서는 모델의 성능이 떨어진다. 때문에 validation data set을 활용하여 학습 중인 모델이 Overfitting 되었는지 확인하여, 학습을 조기에 종료하고, 하이퍼 파라미터를 튜닝하는 등의 조치를 취할 수 있다.

알고리즘이 작동하는 방식
1. 데이터 수집 : 데이터를 수집하고 전처리. 데이터는 feature와 label로 구분 이를 위해 사용되는 데이터는 출력 데이터 세트도 제공되기 때문에 레이블이 지정된 데이터라고 한다. (feature(특징) : 입력되는 정보를 의미합니다. 과거의 담배 가격, 이메일 안의 텍스트 단어 등 현재 알고 있어 예측에 사용되는 정보 / Labels : 예측을 하고자 하는 대상 항목을 의미합니다. 담배의 향후 가격, 사진에 표시되는 사물의 종류 등)
2. 모델 훈련 : 알고리즘은 훈련 데이터를 통해 학습. feature와 label 간의 패턴 또는 관계를 발견하려고 시도.
3. 모델 예측 : 모델이 훈련되면 본 적이 없는 새로운 데이터의 결과를 예측하는 데 사용. 이 새로운 데이터에 대한 입력을 테스트 데이터라고 한다.
4. 평가 : 모델의 예측을 실제 값과 비교하여 모델의 정확도를 평가. 정확도, 정밀도, 재현율, F1 점수(분류용), 평균 절대 오차(MAE), 평균 제곱 오차(MSE), 평균 제곱근 오차(RMSE)(회귀용)와 같은 다양한 메트릭이 모델을 평가하는 데 사용
5. 조정 : 모델의 성능이 만족스럽지 않으면 모델로 돌아가 하이퍼파라미터를 조정하거나 다른 모델을 모두 선택 가능
6. 예측 : 만족스러운 성능이 달성되면 이제 모델을 사용하여 보이지 않는 새로운 데이터를 예측할 수 있다.

------------------------------------------------------------------------------------------------------------------------------------------------------------

