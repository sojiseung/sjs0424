# 1. 머신러닝 기초

- 독립변수 : 종속변수의 변화를 가져오거나 영향을 미치는 원인 변수로써, 결과를 예측을 하게 하거나 차이를 설명하기 위해 사용되는 예측 변수이다 즉, 독립변수는 종속변수의 원인으로 추정되는 변수이다.
- 종속변수 : 독립변수의 영향으로 나타나는 결과가 되는 결과 변수로써, 독립변수의 변화에 따라 변화되는 변수이다.

예시:)
- 수입(독립변수)이 높으면 교육수준(종속변수)이 높아질 수 있다.
- 노인의 건강상태(독립변수)가 좋을수록 행복지수(종속변수)가 높다.
- 가정폭력의 경험(독립변수)이 있는 청소년은 그렇지 않은 청소녀에 비해 비행율(종속변수)이 높을 것 이다.

회귀분석의 의미
회귀분석은 종속변수(목표)와 하나 이상의 독립변수(예측 변수) 간의 미래 사건을 예측하는 방법이다. 예를 들어 난폭운전과 운전자에 의한 교통사고 총 건수 사이의 상관관계을 예측하거나 비즈니스 상황에서는 특정 금액을 광고에 사용했을 때와 그것이 판매에 미치는 영향 사이의 관계를 예측하는 데 사용할 수 있다.

머신러닝 모델의 성능을 측정하는 방법
- 분류모델 : 정확도, 정밀도, 재현율, F1 점수
- 회귀모델 : 평균 절대 오차, 회귀 작업의 평균 제곱근 오차

회귀 및 분류라는 두 가지 유형의 문제에 사용
- 회귀 : 회귀는 대상 또는 종속 변수가 연속적이거나 정렬된 전체 값일 때 사용.
- 분류 : 분류는 대상 변수가 범주형일 때, 간단히 말해서 입력 데이터를 범주로 분류할때 사용.

train, validation, test 데이터셋
머신러닝, 딥러닝 모델을 피팅시키기 위해서는 데이터셋을 크게 세 가지로 분리한다.
- training set(학습 데이터셋) : 모델의 학습을 위해 사용되는 데이터
- validation set(검증 데이터셋) : 모델의 학습 과정에서 성능을 확인하고, 하이퍼 파라미터를 튜닝하는데 사용된다. 여러가지 하이퍼 파라미터로 생성된 모델들 중에 어떤 것이 성능이 좋은지 평가한다. (하이퍼 파라미터란 최적의 훈련 모델을 구현하기 위해 모델에 설정하는 변수로 학습률, 에포크 수(훈련 반복 횟수), 가중치 초기화 등을 결정할 수 있는 모든것)
- test set(테스트 데이터셋) : 생성된 모델의 예측성능을 평가하는데 사용된다.

train / test를 분리하는 이유는 실제로는 모델을 활용하기 위해서는 학습에 사용되지 않은 데이터에 대한 예측을 잘해야한다. 만약, 주어진 데이터에만 치중하여 학습할 경우, 조금이라도 다른 패턴을 가진 데이터에 대해서는 모델의 성능이 떨어진다. 때문에 validation data set을 활용하여 학습 중인 모델이 Overfitting 되었는지 확인하여, 학습을 조기에 종료하고, 하이퍼 파라미터를 튜닝하는 등의 조치를 취할 수 있다.

알고리즘이 작동하는 방식
1. 데이터 수집 : 데이터를 수집하고 전처리. 데이터는 feature와 label로 구분 이를 위해 사용되는 데이터는 출력 데이터 세트도 제공되기 때문에 레이블이 지정된 데이터라고 한다. (feature(특징) : 입력되는 정보를 의미합니다. 과거의 담배 가격, 이메일 안의 텍스트 단어 등 현재 알고 있어 예측에 사용되는 정보 / Labels : 예측을 하고자 하는 대상 항목을 의미합니다. 담배의 향후 가격, 사진에 표시되는 사물의 종류 등)
2. 모델 훈련 : 알고리즘은 훈련 데이터를 통해 학습. feature와 label 간의 패턴 또는 관계를 발견하려고 시도.
3. 모델 예측 : 모델이 훈련되면 본 적이 없는 새로운 데이터의 결과를 예측하는 데 사용. 이 새로운 데이터에 대한 입력을 테스트 데이터라고 한다.
4. 평가 : 모델의 예측을 실제 값과 비교하여 모델의 정확도를 평가. 정확도, 정밀도, 재현율, F1 점수(분류용), 평균 절대 오차(MAE), 평균 제곱 오차(MSE), 평균 제곱근 오차(RMSE)(회귀용)와 같은 다양한 메트릭이 모델을 평가하는 데 사용
5. 조정 : 모델의 성능이 만족스럽지 않으면 모델로 돌아가 하이퍼파라미터를 조정하거나 다른 모델을 모두 선택 가능
6. 예측 : 만족스러운 성능이 달성되면 이제 모델을 사용하여 보이지 않는 새로운 데이터를 예측할 수 있다.

------------------------------------------------------------------------------------------------------------------------------------------------------------
# 지도학습
dicision tree를 이용
- dicision tree는 이해하기 쉽고, 해석 가능하며, 다양한 데이터 타입을 처리할 수 있는 모델 입니다. 단점으로는 과적합의 위험이 있어 적절한 하이퍼파라미터로 튜닝과 앙상블 방법을 통해 단점을 보완 해야합니다.
- X, y = iris.data, iris.target : iris.data(feature(특성)), iris.target(label)
- X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10) : X_train, y_train = 모델 학습용 데이터 샘플, X_test = 모델 예측할 때 사용되는 입력 데이터, y_test = 예측을 완료한 데이터(predict)와 비교하여 성능을 평가하기 위한 데이터
- dt = DecisionTreeClassifier() : dicisiontree를 사용
- dt.fit(X_train, y_train) : 모델 학습
- y_pred = dt.predict(X_test) : X_test를 넣어서 모델을 예측
- accuracy = accuracy_score(y_test, y_pred) : 정확도를 평가하는 코드

LinearRegression을 이용
- mse = mean_squared_error(y_test, y_pred) : y_test와 y_pred(예측)를 비교하여 오차를 계산(오차의 크기는 적을수록 좋다.)

# 비지도학습
비지도학습은 지도 학습과 달리 학습에 사용하는 데이터에 특징(레이블)이 부여되어 있지 않습니다
지도 학습은 기존에 있는 데이터를 기반으로 새로운 데이터에 대한 특징을 추론하는 것을 목표로 한다면, 비지도 학습은 주어진 데이터들이 어떻게 구성되어있는지를 분석하는 것을 목표로 합니다.

K-means : 비지도학습에 속하는 K-means 알고리즘은 쉽게 말해 데이터를 K개의 군집(Cluster)으로 묶는 알고리즘이다.

* 군집이란 쉽게 말해서 비슷한 특성을 지닌 데이터들을 모아놓은 그룹이다.

kmeans = KMeans(n_clusters=3, n_init='auto', random_state=42)
- n_clusters=3 = 그룹을 3개로 나눈다는 뜻
- n_init='auto' = 초기 클러스터 중심을 무작위로 설정하는 횟수를 지정하는 매개변수

labels = kmeans.labels_는 클러스터링 알고리즘을 사용하여 데이터 포인트를 클러스터로 분류한 결과를 저장하는데 사용되는데 labels_는 각 데이터포인트가 속한 클러스터의 라벨(번호)를 나타내는 배열입니다.

# 데이터 전처리 : 스케일링과 정규화
scaler = StandarScaler() : 스케일링과 정규화를 도와주는 standardScaler라는 모듈을 사용
scaled_data = scaler.fit_transform(data) :
- 나는
------------------------------------------------------------------------------------------------------------------------------------------------------------
# 회귀
-경사하강법
  -함수의 값이 낮아지는 방향으로 각 독립변수들의 값을 변형시키면서 함수가 최솟값을 갖도록 하는 독립변수의 값을 탐색 방법

data = {"Size" : np.linspace(500,1000,100)} : 최소값 500부터 최대값 1000까지 총 100개를 만든다.





